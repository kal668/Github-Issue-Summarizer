ðŸ¤– GitHub Issue Summarizer AI Agent
This AI-powered agent fetches open issues from any public GitHub repository and summarizes each issue using a locally-run NLP model (facebook/bart-large-cnn) from Hugging Face. It provides concise summaries directly in your terminal and saves them as a Markdown report. Video Demo: https://youtu.be/7B2lQXm6a6g?si=WFt5YmS_yyZL2vr7

**ðŸš€ Quick Start**
**1. Install Dependencies**
pip install -r requirements.txt

**2. (Optional) Create .env for GitHub Token**
GITHUB_TOKEN=your_github_token_here
If you donâ€™t include a GitHub token, unauthenticated API calls are limited to 60/hour.

**3. Run the Script**
python main.py owner/repo

Example:

python main.py openai/openai-python

**ðŸ“¦ Output**
Summaries printed to the terminal
Markdown file saved as owner_repo_summaries.md (e.g., openai_openai-python_summaries.md)

**ðŸ§  Design Choices**
**Why GitHub + Summarization?**
GitHub issues often contain long technical discussions. Summarizing them helps developers quickly triage and prioritize work â€” especially useful for maintainers or contributors reviewing many issues.

**Why Hugging Face Instead of OpenAI?**
While OpenAIâ€™s GPT-3.5 API is powerful, it has usage limits and requires billing. To avoid quota errors and improve portability, we use a local summarization model from Hugging Face (facebook/bart-large-cnn) which is:
->Free to use
->Runs offline after the initial download
->Widely accepted for summarization tasks

**Why facebook/bart-large-cnn?**
->Pre-trained on CNN/DailyMail summarization corpus
->Balanced trade-off between quality and speed
->Well-suited for issue-style text (semi-formal, technical)

**Why Markdown Output?**
->Easy to share, render in GitHub, or paste into documentation
->Supports integration into automated workflows

**ðŸ§° Tech Stack**
| Component  | Tool/Library            |
| ---------- | ----------------------- |
| Language   | Python 3                |
| GitHub API | requests                |
| NLP Model  | facebook/bart-large-cnn |
| ML Runtime | transformers, torch     |
| Env Config | python-dotenv           |

**ðŸ§ª Example Output (Terminal)**
ðŸ“Œ Issue 1: Unexpected behavior in openai.ChatCompletion.create()
ðŸ”— https://github.com/openai/openai-python/issues/123
ðŸ“ Summary: Passing a custom user ID completes successfully but doesnâ€™t appear in logs or metrics as documented.

**ðŸ’¡ What Iâ€™d Improve with More Time**
->Web-based UI (e.g., Flask or Streamlit interface)
->Interactive CLI (prompt for repo, filters, or labels)
->Batch mode to auto-run daily summaries on selected repos
->Keyword/tag extraction for automated triage
->Post summary as GitHub comment via GitHub API
->Multiple model options (t5-base, pegasus, mistral)
->Model caching and progress bars for better UX

**âœ… Status**
| Feature               | Done |
| --------------------- | ---- |
| GitHub issue fetching | âœ…    |
| Local summarization   | âœ…    |
| Markdown export       | âœ…    |
| CLI repo input        | âœ…    |
| OpenAI-free runtime   | âœ…    |

**ðŸ“Ž License**
MIT License. Use freely, attribution appreciated.
